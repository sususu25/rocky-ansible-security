pipeline {
  agent any

  options {
    timestamps()
    disableConcurrentBuilds()
  }

  parameters {
    // -----------------------------
    // 1) Ïã§Ìñâ Î™®Îìú
    // -----------------------------
    choice(
      name: 'RUN_MODE',
      choices: ['audit', 'enforce'],
      description: 'audit=Ï†êÍ≤ÄÎßå / enforce=Ï°∞Ïπò Ïã§Ìñâ'
    )

    // -----------------------------
    // 2) Ïù∏Î≤§ÌÜ†Î¶¨ ÏûÖÎ†• Î∞©Ïãù
    // -----------------------------
    choice(
      name: 'INVENTORY_MODE',
      choices: ['manual', 'tf_artifact'],
      description: 'manual=UIÏóêÏÑú ÏßÅÏ†ë ÏûÖÎ†• / tf_artifact=Terraform JobÏùò tf_output.json ÏÇ¨Ïö©'
    )

    // -----------------------------
    // 3) ÏàòÎèô ÏûÖÎ†• Î™®ÎìúÏö© ÌååÎùºÎØ∏ÌÑ∞
    // -----------------------------
    string(
      name: 'BASTION_IP',
      defaultValue: '',
      description: 'INVENTORY_MODE=manualÏùº Îïå bastion Í≥µÏù∏ IP (Ïòà: 133.186.xxx.xxx)'
    )

    text(
      name: 'TARGET_PRIVATE_IPS',
      defaultValue: '',
      description: '''INVENTORY_MODE=manualÏùº Îïå ÎåÄÏÉÅ ÏÑúÎ≤Ñ private IP ÏûÖÎ†•
ÏòàÏãú(ÏâºÌëú/Í≥µÎ∞±/Ï§ÑÎ∞îÍøà Î™®Îëê Í∞ÄÎä•):
10.0.2.45,10.0.2.36
ÎòêÎäî
10.0.2.45
10.0.2.36'''
    )

    // -----------------------------
    // 4) Terraform ÏïÑÌã∞Ìå©Ìä∏ Î™®ÎìúÏö© ÌååÎùºÎØ∏ÌÑ∞
    // -----------------------------
    string(
      name: 'TF_JOB_NAME',
      defaultValue: 'Terraform Job',
      description: 'tf_output.jsonÏùÑ Í∞ÄÏ†∏Ïò¨ Terraform Jenkins Job Ïù¥Î¶Ñ'
    )

    string(
      name: 'TF_BUILD_NUMBER',
      defaultValue: '',
      description: 'ÎπÑÏö∞Î©¥ ÎßàÏßÄÎßâ ÏÑ±Í≥µ ÎπåÎìú(lastSuccessful), Ïà´Ïûê ÏûÖÎ†• Ïãú Ìï¥Îãπ ÎπåÎìúÎ≤àÌò∏ÏóêÏÑú Í∞ÄÏ†∏Ïò¥'
    )

    // -----------------------------
    // 5) Git Î∏åÎûúÏπò / Ïã§Ìñâ ÏòµÏÖò
    // -----------------------------
    string(
      name: 'GIT_BRANCH',
      defaultValue: 'main',
      description: 'Ansible Î†àÌè¨ÏóêÏÑú checkoutÌï† Î∏åÎûúÏπòÎ™Ö (Ïòà: feature/xxx)'
    )

    string(
      name: 'ANSIBLE_LIMIT',
      defaultValue: '',
      description: 'ÏÑ†ÌÉù: ÌäπÏ†ï Ìò∏Ïä§Ìä∏Îßå Ïã§ÌñâÌïòÍ≥† Ïã∂ÏùÑ Îïå (Ïòà: rocky-01)'
    )

    booleanParam(
      name: 'DRY_PING_ONLY',
      defaultValue: false,
      description: 'trueÎ©¥ ansible ping ÌÖåÏä§Ìä∏ÍπåÏßÄÎßå ÏàòÌñâÌïòÍ≥† ÌîåÎ†àÏù¥Î∂ÅÏùÄ Ïã§ÌñâÌïòÏßÄ ÏïäÏùå'
    )
  }

  environment {
    // JenkinsÏóê Îì±Î°ùÎêú SSH Credential ID (SSH Username with private key)
    SSH_CRED_ID = 'bastion-ssh-key'
    GENERATED_DIR = 'generated'
    GENERATED_INVENTORY = 'generated/hosts.runtime.ini'
    GENERATED_TF_JSON = 'generated/tf_output.json'
  }

  stages {
    stage('Checkout Ansible Repo') {
      steps {
        checkout([
          $class: 'GitSCM',
          branches: [[name: "*/${params.GIT_BRANCH}"]],
          userRemoteConfigs: [[url: 'https://github.com/sususu25/rocky-ansible-security.git']]
        ])
      }
    }

    stage('Validate Params') {
      steps {
        script {
          if (params.INVENTORY_MODE == 'manual') {
            if (!params.BASTION_IP?.trim()) {
              error("INVENTORY_MODE=manual Ïù∏Îç∞ BASTION_IPÍ∞Ä ÎπÑÏñ¥ÏûàÏäµÎãàÎã§.")
            }
            if (!params.TARGET_PRIVATE_IPS?.trim()) {
              error("INVENTORY_MODE=manual Ïù∏Îç∞ TARGET_PRIVATE_IPSÍ∞Ä ÎπÑÏñ¥ÏûàÏäµÎãàÎã§.")
            }
          }

          if (params.INVENTORY_MODE == 'tf_artifact') {
            if (!params.TF_JOB_NAME?.trim()) {
              error("INVENTORY_MODE=tf_artifact Ïù∏Îç∞ TF_JOB_NAMEÏù¥ ÎπÑÏñ¥ÏûàÏäµÎãàÎã§.")
            }
          }

          if (!(params.RUN_MODE in ['audit', 'enforce'])) {
            error("RUN_MODEÎäî audit ÎòêÎäî enforce Ïó¨Ïïº Ìï©ÎãàÎã§.")
          }
        }
      }
    }

    stage('Prepare Workspace') {
      steps {
        sh '''
          set -e
          mkdir -p "${GENERATED_DIR}"
          mkdir -p collected_logs
          echo "Workspace prepared"
        '''
      }
    }

    stage('Fetch Terraform Output (tf_artifact mode)') {
      when {
        expression { params.INVENTORY_MODE == 'tf_artifact' }
      }
      steps {
        script {
          if (params.TF_BUILD_NUMBER?.trim()) {
            // ÌäπÏ†ï ÎπåÎìú Î≤àÌò∏ÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞
            copyArtifacts(
              projectName: params.TF_JOB_NAME,
              selector: specific(params.TF_BUILD_NUMBER.trim()),
              filter: 'tf_output.json',
              target: env.GENERATED_DIR,
              flatten: true
            )
          } else {
            // ÎßàÏßÄÎßâ ÏÑ±Í≥µ ÎπåÎìúÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞
            copyArtifacts(
              projectName: params.TF_JOB_NAME,
              selector: lastSuccessful(),
              filter: 'tf_output.json',
              target: env.GENERATED_DIR,
              flatten: true
            )
          }

          sh '''
            set -e
            test -f "${GENERATED_TF_JSON}"
            echo "Fetched tf_output.json:"
            ls -l "${GENERATED_TF_JSON}"
          '''
        }
      }
    }

    stage('Generate Runtime Inventory') {
      steps {
        withCredentials([
          sshUserPrivateKey(
            credentialsId: env.SSH_CRED_ID,
            keyFileVariable: 'SSH_KEY_FILE',
            usernameVariable: 'SSH_USER'
          )
        ]) {
          script {
            def bastionIp = ''
            def targetIps = []

            if (params.INVENTORY_MODE == 'manual') {
              bastionIp = params.BASTION_IP.trim()

              // ÏâºÌëú/Í≥µÎ∞±/Ï§ÑÎ∞îÍøà Î™®Îëê ÌóàÏö©
              targetIps = params.TARGET_PRIVATE_IPS
                .split(/[\\s,]+/)
                .collect { it.trim() }
                .findAll { it }

            } else {
              // tf_output.json ÌååÏã±
              def tfRaw = readFile(file: env.GENERATED_TF_JSON)
              def tf = new groovy.json.JsonSlurperClassic().parseText(tfRaw)

              bastionIp = tf?.bastion_fip?.value?.toString()?.trim()

              def backendMap = tf?.backend_mgmt_private_ips?.value
              if (!backendMap || !(backendMap instanceof Map)) {
                error("tf_output.jsonÏóêÏÑú backend_mgmt_private_ips.value(map)Î•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
              }

              targetIps = backendMap.values()
                .collect { it.toString().trim() }
                .findAll { it }

              if (!bastionIp) {
                error("tf_output.jsonÏóêÏÑú bastion_fip.valueÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
              }
            }

            if (!bastionIp) {
              error("Bastion IPÍ∞Ä ÎπÑÏñ¥ ÏûàÏäµÎãàÎã§.")
            }
            if (!targetIps || targetIps.size() == 0) {
              error("ÎåÄÏÉÅ ÏÑúÎ≤Ñ IPÍ∞Ä ÎπÑÏñ¥ ÏûàÏäµÎãàÎã§.")
            }

            // Ï§ëÎ≥µ Ï†úÍ±∞ (ÏàúÏÑú Ïú†ÏßÄ)
            def uniqueTargetIps = []
            targetIps.each { ip ->
              if (!uniqueTargetIps.contains(ip)) {
                uniqueTargetIps << ip
              }
            }

            // host Ïù¥Î¶Ñ ÏûêÎèô ÏÉùÏÑ± rocky-01 ~ n
            def hostLines = []
            for (int i = 0; i < uniqueTargetIps.size(); i++) {
              def idx = i + 1
              def hostName = String.format("rocky-%02d", idx)
              hostLines << "${hostName} ansible_host=${uniqueTargetIps[i]}"
            }

            // ProxyCommand Íµ¨ÏÑ± (Í∞ôÏùÄ ÌÇ§Î°ú bastion -> backend)
            // %h, %p Îäî ÏõêÍ≤© Ìò∏Ïä§Ìä∏/Ìè¨Ìä∏
            def proxyCmd = "-o ProxyCommand=\\\"ssh -W %h:%p -o StrictHostKeyChecking=no -i ${SSH_KEY_FILE} ${SSH_USER}@${bastionIp}\\\""

            def inventoryContent = """[rocky_servers]
${hostLines.join('\n')}

[rocky_servers:vars]
ansible_user=${SSH_USER}
ansible_ssh_private_key_file=${SSH_KEY_FILE}
ansible_become=true
ansible_become_method=sudo
ansible_become_user=root
ansible_ssh_common_args=${proxyCmd}
"""

            writeFile(file: env.GENERATED_INVENTORY, text: inventoryContent)

            echo "Generated inventory => ${env.GENERATED_INVENTORY}"
            echo "Bastion IP => ${bastionIp}"
            echo "Target count => ${uniqueTargetIps.size()}"
            echo "Targets => ${uniqueTargetIps.join(', ')}"
          }
        }
      }
    }

    stage('Show Inventory (sanity check)') {
      steps {
        sh '''
          set -e
          echo "===== Generated Inventory ====="
          cat "${GENERATED_INVENTORY}"
          echo "==============================="
        '''
      }
    }

    stage('Ansible Ping Test') {
      steps {
        withCredentials([
          sshUserPrivateKey(
            credentialsId: env.SSH_CRED_ID,
            keyFileVariable: 'SSH_KEY_FILE',
            usernameVariable: 'SSH_USER'
          )
        ]) {
          script {
            def limitOpt = params.ANSIBLE_LIMIT?.trim() ? "--limit '${params.ANSIBLE_LIMIT.trim()}'" : ""
            sh """
              set -e
              export ANSIBLE_HOST_KEY_CHECKING=False
              ansible --version
              ansible -i '${env.GENERATED_INVENTORY}' rocky_servers -m ping ${limitOpt}
            """
          }
        }
      }
    }

    stage('Run Playbook') {
      when {
        expression { return !params.DRY_PING_ONLY }
      }
      steps {
        withCredentials([
          sshUserPrivateKey(
            credentialsId: env.SSH_CRED_ID,
            keyFileVariable: 'SSH_KEY_FILE',
            usernameVariable: 'SSH_USER'
          )
        ]) {
          script {
            def playbookFile = (params.RUN_MODE == 'audit') ? 'playbooks/security_audit.yml' : 'playbooks/security_check.yml'
            def limitOpt = params.ANSIBLE_LIMIT?.trim() ? "--limit '${params.ANSIBLE_LIMIT.trim()}'" : ""

            sh """
              set -e
              export ANSIBLE_HOST_KEY_CHECKING=False
              ansible-playbook -i '${env.GENERATED_INVENTORY}' '${playbookFile}' ${limitOpt}
            """
          }
        }
      }
    }
  }

  post {
    always {
      archiveArtifacts artifacts: 'generated/**,collected_logs/**', allowEmptyArchive: true
      echo 'üßπ Pipeline finished'
    }
    success {
      echo '‚úÖ Pipeline SUCCESS'
    }
    failure {
      echo '‚ùå Pipeline FAILED'
    }
  }
}